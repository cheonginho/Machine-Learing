{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "file_data   = \"mnist.csv\"\n",
    "handle_file = open(file_data, \"r\")\n",
    "data        = handle_file.readlines()\n",
    "handle_file.close()\n",
    "\n",
    "#train data 정의\n",
    "train_data= data[:1000]\n",
    "num_train = len(train_data)\n",
    "\n",
    "#test data 정의\n",
    "test_data= data[1000:10000]\n",
    "num_test = len(test_data)\n",
    "\n",
    "#normalize func\n",
    "def normalize(data):\n",
    "\n",
    "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
    "\n",
    "    return(data_normalized)\n",
    "\n",
    "size_row = 28\n",
    "size_col = 28\n",
    "\n",
    "list_train_image  = np.empty((size_row * size_col, num_train), dtype=float)\n",
    "list_train_label  = np.empty(num_train, dtype=int)\n",
    "\n",
    "list_test_image  = np.empty((size_row * size_col, num_test), dtype=float)\n",
    "list_test_label  = np.empty(num_test, dtype=int)\n",
    "\n",
    "\n",
    "#iteration parameter init\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "for line in train_data:\n",
    "\n",
    "    line_data   = line.split(',')\n",
    "    label       = line_data[0]\n",
    "    im_vector   = np.asfarray(line_data[1:])\n",
    "    im_vector   = normalize(im_vector)\n",
    "\n",
    "    list_train_label[count1]       = label\n",
    "    list_train_image[:, count1]    = im_vector\n",
    "\n",
    "    count1 += 1\n",
    "    \n",
    "for line in test_data:\n",
    "    \n",
    "    line_data = line.split(',')\n",
    "    label = line_data[0]\n",
    "    im_vector =np.asfarray(line_data[1:])\n",
    "    im_vector = normalize(im_vector)\n",
    "    \n",
    "    list_test_label[count2] = label\n",
    "    list_test_image[:,count2] = im_vector\n",
    "    \n",
    "    count2 +=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_image = list_train_image.T\n",
    "list_test_image = list_test_image.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lambda = 1\n",
    "iterations = 100\n",
    "alpha = 0.01\n",
    "num_examples = len(list_train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/ ( 1 + np.exp(-z) )\n",
    "    \n",
    "def sigmoid_der(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    k=(np.exp(x)-np.max(x))\n",
    "    return k/np.sum(k)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train_image.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.45490196,\n",
       "       0.49019608, 0.67058824, 1.        , 1.        , 0.58823529,\n",
       "       0.36470588, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.6627451 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.85490196, 0.11764706,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.83529412, 0.55686275, 0.69019608,\n",
       "       0.99215686, 0.99215686, 0.47843137, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.20392157, 0.98039216, 0.99215686, 0.82352941, 0.1254902 ,\n",
       "       0.04705882, 0.        , 0.02352941, 0.80784314, 0.99215686,\n",
       "       0.54901961, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.30196078, 0.98431373,\n",
       "       0.82352941, 0.09803922, 0.        , 0.        , 0.        ,\n",
       "       0.47843137, 0.97254902, 0.99215686, 0.25490196, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.07058824, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.81960784, 0.99215686,\n",
       "       0.99215686, 0.25490196, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.45882353, 0.96862745, 0.99215686, 0.77647059, 0.03921569,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.29803922, 0.96862745, 0.99215686,\n",
       "       0.90588235, 0.24705882, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.50196078, 0.99215686, 0.99215686, 0.56470588, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.69019608, 0.96470588, 0.99215686,\n",
       "       0.62352941, 0.04705882, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.09803922,\n",
       "       0.91764706, 0.99215686, 0.91372549, 0.1372549 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.77647059, 0.99215686, 0.99215686,\n",
       "       0.55294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.30588235,\n",
       "       0.97254902, 0.99215686, 0.74117647, 0.04705882, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0745098 , 0.78431373, 0.99215686, 0.99215686,\n",
       "       0.55294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.5254902 ,\n",
       "       0.99215686, 0.99215686, 0.67843137, 0.04705882, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.97254902, 0.99215686, 0.99215686,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.97254902, 0.99215686, 0.99215686, 0.16862745, 0.07843137,\n",
       "       0.07843137, 0.07843137, 0.07843137, 0.01960784, 0.        ,\n",
       "       0.01960784, 0.07843137, 0.07843137, 0.14509804, 0.58823529,\n",
       "       0.58823529, 0.58823529, 0.57647059, 0.03921569, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97254902, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.65882353, 0.56078431, 0.65098039, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.48235294, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.68235294, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.97647059, 0.96862745,\n",
       "       0.96862745, 0.6627451 , 0.45882353, 0.45882353, 0.22352941,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4627451 , 0.48235294, 0.48235294, 0.48235294, 0.65098039,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.60784314, 0.48235294,\n",
       "       0.48235294, 0.16078431, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train_image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wb(list_train_image,hidden_dim,output_dim):\n",
    "    wb_model = {}\n",
    "    input_dim = list_train_image.shape[1]\n",
    "    wb_model['w1'] = np.random.randn(input_dim, hidden_dim) / np.sqrt(input_dim)\n",
    "    wb_model['b1'] = np.zeros((1, hidden_dim))\n",
    "    wb_model['w2'] = np.random.randn(hidden_dim, hidden_dim) / np.sqrt(hidden_dim)\n",
    "    wb_model['b2'] = np.zeros((1, hidden_dim))\n",
    "    wb_model['w3'] = np.random.randn(hidden_dim, output_dim) / np.sqrt(hidden_dim)\n",
    "    wb_model['b3'] = np.zeros((1, output_dim))\n",
    "    return wb_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(model,X):\n",
    "    w1, b1, w2, b2, w3, b3 = model['w1'], model['b1'], model['w2'], model['b2'], model['w3'], model['b3']\n",
    "    #forward_prop\n",
    "    a1 = X.dot(w1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = z1.dot(w2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = z2.dot(w3) + b3\n",
    "    output = Softmax(a3)\n",
    "    return a1,z1,a2,z2,a3,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(model,X,y,reg_lambda):\n",
    "    num_examples = X.shape[0]\n",
    "    w1, b1, w2, b2, w3, b3 = model['w1'], model['b1'], model['w2'], model['b2'], model['w3'], model['b3']\n",
    "    # Forward propagation to calculate our predictions\n",
    "    a1, z1, a2, z2, a3, output = forward_prop(model, X)\n",
    "    probs = output / np.sum(output, axis=1, keepdims=True)\n",
    "    # Calculating the loss\n",
    "    corect_logprobs = -np.log(probs[range(num_examples), y])\n",
    "    loss = np.sum(corect_logprobs)\n",
    "    # Add regulatization term to loss (optional)\n",
    "    loss += reg_lambda/2 * (np.sum(np.square(w1)) + np.sum(np.square(w2)) + np.sum(np.square(w3)))\n",
    "    return 1.0 /num_examples * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(X,y,model,a1,z1,a2,z2,a3,output,reg_lambda):\n",
    "    delta3 = output\n",
    "    delta3[range(X.shape[0]), y] -= 1  #yhat - y\n",
    "    dW3 = (z2.T).dot(delta3)\n",
    "    db3 = np.sum(delta3, axis=0, keepdims=True)\n",
    "    delta2 = delta3.dot(model['w3'].T) * sigmoid_der(z2)\n",
    "    dW2 = np.dot(a1.T, delta2)\n",
    "    db2 = np.sum(delta2, axis=0)\n",
    "    #delta2 = delta3.dot(model['W2'].T) * (1 - np.power(a1, 2)) #if tanh\n",
    "    delta1 = delta2.dot(model['w2'].T) * sigmoid_der(z1)\n",
    "    dW1 = np.dot(X.T, delta1)\n",
    "    db1 = np.sum(delta1, axis=0)\n",
    "    # Add regularization terms\n",
    "    dW3 += reg_lambda * model['w3']\n",
    "    dW2 += reg_lambda * model['w2']\n",
    "    dW1 += reg_lambda * model['w1']\n",
    "    return dW1, dW2, dW3, db1, db2, db3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(X, Y):\n",
    "        # test the model on the training dataset\n",
    "        total_correct = 0\n",
    "        for n in range(len(X)):\n",
    "            y = Y[n]\n",
    "            x = X[n][:]\n",
    "            prediction = np.argmax(forward_prop(x,y)['output'])\n",
    "            if (prediction == y):\n",
    "                total_correct += 1 \n",
    "        print('Accuarcy Test: ',total_correct/len(X_test))\n",
    "        return total_correct/np.float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, iterations, reg_lambda, alpha):\n",
    "    # Batch gradient descent\n",
    "    done = False\n",
    "    previous_loss = float('inf')\n",
    "    i = 0\n",
    "    losses = []\n",
    "     #comment out while performance testing\n",
    "    while i < iterations:\n",
    "        #feed forward\n",
    "        a1,z1,a2,z2,a3,output = forward_prop(model, X)\n",
    "        #backpropagation\n",
    "        dW1, dW2, dW3, db1, db2, db3 = backprop(X,y,model,a1,z1,a2,z2,a3,output,reg_lambda)\n",
    "        #update weights and biases\n",
    "        model['w1'] -= alpha * dW1\n",
    "        model['b1'] -= alpha * db1\n",
    "        model['w2'] -= alpha * dW2\n",
    "        model['b2'] -= alpha * db2\n",
    "        model['w3'] -= alpha * dW3\n",
    "        model['b3'] -= alpha * db3\n",
    "        \n",
    "        loss = cal_loss(model, X, y, reg_lambda)\n",
    "        losses.append(loss)\n",
    "        #uncomment once testing finished, return mod val to 1000\n",
    "        previous_loss = loss\n",
    "        i += 1\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihbor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#input_dim = 784\n",
    "#output_dim = 10\n",
    "wb_model = build_wb(list_train_image,100,10)\n",
    "wb_model_t = build_wb(list_test_image,100,10)\n",
    "wb_model , losses = train(wb_model,list_train_image,list_train_label,iterations,reg_lambda,alpha)\n",
    "wb_model_t, losses_t = train(wb_model_t,list_test_image,list_test_label,iterations,reg_lambda,alpha)\n",
    "output = forward_prop(wb_model,list_train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bf1e446888>]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(losses_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
