{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "file_data   = \"mnist.csv\"\n",
    "handle_file = open(file_data, \"r\")\n",
    "data        = handle_file.readlines()\n",
    "handle_file.close()\n",
    "\n",
    "#train data 정의\n",
    "train_data= data[:1000]\n",
    "num_train = len(train_data)\n",
    "\n",
    "#test data 정의\n",
    "test_data= data[1000:10000]\n",
    "num_test = len(test_data)\n",
    "\n",
    "#normalize func\n",
    "def normalize(data):\n",
    "\n",
    "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
    "\n",
    "    return(data_normalized)\n",
    "\n",
    "size_row = 28\n",
    "size_col = 28\n",
    "\n",
    "list_train_image  = np.empty((size_row * size_col, num_train), dtype=float)\n",
    "list_train_label  = np.empty(num_train, dtype=int)\n",
    "\n",
    "list_test_image  = np.empty((size_row * size_col, num_test), dtype=float)\n",
    "list_test_label  = np.empty(num_test, dtype=int)\n",
    "\n",
    "\n",
    "#iteration parameter init\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "for line in train_data:\n",
    "\n",
    "    line_data   = line.split(',')\n",
    "    label       = line_data[0]\n",
    "    im_vector   = np.asfarray(line_data[1:])\n",
    "    im_vector   = normalize(im_vector)\n",
    "\n",
    "    list_train_label[count1]       = label\n",
    "    list_train_image[:, count1]    = im_vector\n",
    "\n",
    "    count1 += 1\n",
    "    \n",
    "for line in test_data:\n",
    "    \n",
    "    line_data = line.split(',')\n",
    "    label = line_data[0]\n",
    "    im_vector =np.asfarray(line_data[1:])\n",
    "    im_vector = normalize(im_vector)\n",
    "    \n",
    "    list_test_label[count2] = label\n",
    "    list_test_image[:,count2] = im_vector\n",
    "    \n",
    "    count2 +=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_image = list_train_image.T\n",
    "list_test_image = list_test_image.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lambda = 1\n",
    "iterations = 100\n",
    "alpha = 0.01\n",
    "num_examples = len(list_train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/ ( 1 + np.exp(z) )\n",
    "    \n",
    "def sigmoid_der(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    k=(np.exp(x)-np.max(x))\n",
    "    return k/np.sum(k)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train_image.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.45490196,\n",
       "       0.49019608, 0.67058824, 1.        , 1.        , 0.58823529,\n",
       "       0.36470588, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.6627451 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.85490196, 0.11764706,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.83529412, 0.55686275, 0.69019608,\n",
       "       0.99215686, 0.99215686, 0.47843137, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.20392157, 0.98039216, 0.99215686, 0.82352941, 0.1254902 ,\n",
       "       0.04705882, 0.        , 0.02352941, 0.80784314, 0.99215686,\n",
       "       0.54901961, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.30196078, 0.98431373,\n",
       "       0.82352941, 0.09803922, 0.        , 0.        , 0.        ,\n",
       "       0.47843137, 0.97254902, 0.99215686, 0.25490196, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.07058824, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.81960784, 0.99215686,\n",
       "       0.99215686, 0.25490196, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.45882353, 0.96862745, 0.99215686, 0.77647059, 0.03921569,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.29803922, 0.96862745, 0.99215686,\n",
       "       0.90588235, 0.24705882, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.50196078, 0.99215686, 0.99215686, 0.56470588, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.69019608, 0.96470588, 0.99215686,\n",
       "       0.62352941, 0.04705882, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.09803922,\n",
       "       0.91764706, 0.99215686, 0.91372549, 0.1372549 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.77647059, 0.99215686, 0.99215686,\n",
       "       0.55294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.30588235,\n",
       "       0.97254902, 0.99215686, 0.74117647, 0.04705882, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0745098 , 0.78431373, 0.99215686, 0.99215686,\n",
       "       0.55294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.5254902 ,\n",
       "       0.99215686, 0.99215686, 0.67843137, 0.04705882, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.97254902, 0.99215686, 0.99215686,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.97254902, 0.99215686, 0.99215686, 0.16862745, 0.07843137,\n",
       "       0.07843137, 0.07843137, 0.07843137, 0.01960784, 0.        ,\n",
       "       0.01960784, 0.07843137, 0.07843137, 0.14509804, 0.58823529,\n",
       "       0.58823529, 0.58823529, 0.57647059, 0.03921569, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97254902, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.65882353, 0.56078431, 0.65098039, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.48235294, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.68235294, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.97647059, 0.96862745,\n",
       "       0.96862745, 0.6627451 , 0.45882353, 0.45882353, 0.22352941,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4627451 , 0.48235294, 0.48235294, 0.48235294, 0.65098039,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.60784314, 0.48235294,\n",
       "       0.48235294, 0.16078431, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train_image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wb(list_train_image,hidden_dim,output_dim):\n",
    "    wb_model = {}\n",
    "    input_dim = list_train_image.shape[1]\n",
    "    wb_model['w1'] = np.random.randn(input_dim, hidden_dim) / np.sqrt(input_dim)\n",
    "    wb_model['b1'] = np.zeros((1, hidden_dim))\n",
    "    wb_model['w2'] = np.random.randn(hidden_dim, hidden_dim) / np.sqrt(hidden_dim)\n",
    "    wb_model['b2'] = np.zeros((1, hidden_dim))\n",
    "    wb_model['w3'] = np.random.randn(hidden_dim, output_dim) / np.sqrt(hidden_dim)\n",
    "    wb_model['b3'] = np.zeros((1, output_dim))\n",
    "    return wb_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(model,X):\n",
    "    w1, b1, w2, b2, w3, b3 = model['w1'], model['b1'], model['w2'], model['b2'], model['w3'], model['b3']\n",
    "    #forward_prop\n",
    "    a1 = X.dot(w1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = z1.dot(w2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = z2.dot(w3) + b3\n",
    "    output = Softmax(a3)\n",
    "    return a1,z1,a2,z2,a3,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(model,X,y,reg_lambda):\n",
    "    num_examples = X.shape[0]\n",
    "    w1, b1, w2, b2, w3, b3 = model['w1'], model['b1'], model['w2'], model['b2'], model['w3'], model['b3']\n",
    "    # Forward propagation to calculate our predictions\n",
    "    a1, z1, a2, z2, a3, output = forward_prop(model, X)\n",
    "    probs = output / np.sum(output, axis=1, keepdims=True)\n",
    "    # Calculating the loss\n",
    "    corect_logprobs = -np.log(probs[range(num_examples), y])\n",
    "    loss = np.sum(corect_logprobs)\n",
    "    # Add regulatization term to loss (optional)\n",
    "    loss += reg_lambda/2 * (np.sum(np.square(w1)) + np.sum(np.square(w2)) + np.sum(np.square(w3)))\n",
    "    return 1.0 /num_examples * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(X,y,model,a1,z1,a2,z2,a3,output,reg_lambda):\n",
    "    delta3 = output\n",
    "    delta3[range(X.shape[0]), y] -= 1  #yhat - y\n",
    "    dW3 = (z2.T).dot(delta3)\n",
    "    db3 = np.sum(delta3, axis=0, keepdims=True)\n",
    "    delta2 = delta3.dot(model['w3'].T) * sigmoid_der(z2)\n",
    "    dW2 = np.dot(a1.T, delta2)\n",
    "    db2 = np.sum(delta2, axis=0)\n",
    "    #delta2 = delta3.dot(model['W2'].T) * (1 - np.power(a1, 2)) #if tanh\n",
    "    delta1 = delta2.dot(model['w2'].T) * sigmoid_der(z1)\n",
    "    dW1 = np.dot(X.T, delta1)\n",
    "    db1 = np.sum(delta1, axis=0)\n",
    "    # Add regularization terms\n",
    "    dW3 += reg_lambda * model['w3']\n",
    "    dW2 += reg_lambda * model['w2']\n",
    "    dW1 += reg_lambda * model['w1']\n",
    "    return dW1, dW2, dW3, db1, db2, db3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(X, Y):\n",
    "        # test the model on the training dataset\n",
    "        total_correct = 0\n",
    "        for n in range(len(X)):\n",
    "            y = Y[n]\n",
    "            x = X[n][:]\n",
    "            prediction = np.argmax(forward_prop(x,y)['output'])\n",
    "            if (prediction == y):\n",
    "                total_correct += 1 \n",
    "        print('Accuarcy Test: ',total_correct/len(X_test))\n",
    "        return total_correct/np.float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, iterations, reg_lambda, alpha):\n",
    "    # Batch gradient descent\n",
    "    done = False\n",
    "    previous_loss = float('inf')\n",
    "    i = 0\n",
    "    losses = []\n",
    "     #comment out while performance testing\n",
    "    while i < iterations:\n",
    "        #feed forward\n",
    "        a1,z1,a2,z2,a3,output = forward_prop(model, X)\n",
    "        #backpropagation\n",
    "        dW1, dW2, dW3, db1, db2, db3 = backprop(X,y,model,a1,z1,a2,z2,a3,output,reg_lambda)\n",
    "        #update weights and biases\n",
    "        model['w1'] -= alpha * dW1\n",
    "        model['b1'] -= alpha * db1\n",
    "        model['w2'] -= alpha * dW2\n",
    "        model['b2'] -= alpha * db2\n",
    "        model['w3'] -= alpha * dW3\n",
    "        model['b3'] -= alpha * db3\n",
    "        \n",
    "        loss = cal_loss(model, X, y, reg_lambda)\n",
    "        losses.append(loss)\n",
    "        #uncomment once testing finished, return mod val to 1000\n",
    "        previous_loss = loss\n",
    "        i += 1\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihbor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#input_dim = 784\n",
    "#output_dim = 10\n",
    "wb_model = build_wb(list_train_image,50,10)\n",
    "wb_model_t = build_wb(list_test_image,50,10)\n",
    "wb_model , losses = train(wb_model,list_train_image,list_train_label,iterations,reg_lambda,alpha)\n",
    "wb_model_t, losses_t = train(wb_model_t,list_test_image,list_test_label,iterations,reg_lambda,alpha)\n",
    "output = forward_prop(wb_model,list_train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
