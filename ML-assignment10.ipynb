{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "file_data   = \"mnist.csv\"\n",
    "handle_file = open(file_data, \"r\")\n",
    "data        = handle_file.readlines()\n",
    "handle_file.close()\n",
    "\n",
    "#train data 정의\n",
    "train_data= data[:1000]\n",
    "num_train = len(train_data)\n",
    "\n",
    "#test data 정의\n",
    "test_data= data[1000:10000]\n",
    "num_test = len(test_data)\n",
    "\n",
    "#normalize func\n",
    "def normalize(data):\n",
    "\n",
    "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
    "\n",
    "    return(data_normalized)\n",
    "\n",
    "size_row = 28\n",
    "size_col = 28\n",
    "\n",
    "list_train_image  = np.empty((size_row * size_col, num_train), dtype=float)\n",
    "list_train_label  = np.empty(num_train, dtype=int)\n",
    "\n",
    "list_test_image  = np.empty((size_row * size_col, num_test), dtype=float)\n",
    "list_test_label  = np.empty(num_test, dtype=int)\n",
    "\n",
    "\n",
    "#iteration parameter init\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "for line in train_data:\n",
    "\n",
    "    line_data   = line.split(',')\n",
    "    label       = line_data[0]\n",
    "    im_vector   = np.asfarray(line_data[1:])\n",
    "    im_vector   = normalize(im_vector)\n",
    "\n",
    "    list_train_label[count1]       = label\n",
    "    list_train_image[:, count1]    = im_vector\n",
    "\n",
    "    count1 += 1\n",
    "    \n",
    "for line in test_data:\n",
    "    \n",
    "    line_data = line.split(',')\n",
    "    label = line_data[0]\n",
    "    im_vector =np.asfarray(line_data[1:])\n",
    "    im_vector = normalize(im_vector)\n",
    "    \n",
    "    list_test_label[count2] = label\n",
    "    list_test_image[:,count2] = im_vector\n",
    "    \n",
    "    count2 +=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_image = list_train_image.T\n",
    "list_test_image = list_test_image.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lambda = 1\n",
    "iterations = 100\n",
    "alpha = 0.01\n",
    "num_examples = len(list_train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/ ( 1 + np.exp(z) )\n",
    "    \n",
    "def sigmoid_der(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    k=(np.exp(x)-np.max(x))\n",
    "    return k/np.sum(k)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train_image.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.45490196,\n",
       "       0.49019608, 0.67058824, 1.        , 1.        , 0.58823529,\n",
       "       0.36470588, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.6627451 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.85490196, 0.11764706,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.83529412, 0.55686275, 0.69019608,\n",
       "       0.99215686, 0.99215686, 0.47843137, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.20392157, 0.98039216, 0.99215686, 0.82352941, 0.1254902 ,\n",
       "       0.04705882, 0.        , 0.02352941, 0.80784314, 0.99215686,\n",
       "       0.54901961, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.30196078, 0.98431373,\n",
       "       0.82352941, 0.09803922, 0.        , 0.        , 0.        ,\n",
       "       0.47843137, 0.97254902, 0.99215686, 0.25490196, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.07058824, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.81960784, 0.99215686,\n",
       "       0.99215686, 0.25490196, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.45882353, 0.96862745, 0.99215686, 0.77647059, 0.03921569,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.29803922, 0.96862745, 0.99215686,\n",
       "       0.90588235, 0.24705882, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.50196078, 0.99215686, 0.99215686, 0.56470588, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.69019608, 0.96470588, 0.99215686,\n",
       "       0.62352941, 0.04705882, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.09803922,\n",
       "       0.91764706, 0.99215686, 0.91372549, 0.1372549 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.77647059, 0.99215686, 0.99215686,\n",
       "       0.55294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.30588235,\n",
       "       0.97254902, 0.99215686, 0.74117647, 0.04705882, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0745098 , 0.78431373, 0.99215686, 0.99215686,\n",
       "       0.55294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.5254902 ,\n",
       "       0.99215686, 0.99215686, 0.67843137, 0.04705882, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.97254902, 0.99215686, 0.99215686,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.97254902, 0.99215686, 0.99215686, 0.16862745, 0.07843137,\n",
       "       0.07843137, 0.07843137, 0.07843137, 0.01960784, 0.        ,\n",
       "       0.01960784, 0.07843137, 0.07843137, 0.14509804, 0.58823529,\n",
       "       0.58823529, 0.58823529, 0.57647059, 0.03921569, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97254902, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.65882353, 0.56078431, 0.65098039, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.48235294, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.68235294, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.97647059, 0.96862745,\n",
       "       0.96862745, 0.6627451 , 0.45882353, 0.45882353, 0.22352941,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4627451 , 0.48235294, 0.48235294, 0.48235294, 0.65098039,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.60784314, 0.48235294,\n",
       "       0.48235294, 0.16078431, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train_image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wb(list_train_image,hidden_dim,output_dim):\n",
    "    wb_model = {}\n",
    "    input_dim = list_train_image.shape[1]\n",
    "    wb_model['w1'] = np.random.randn(input_dim, hidden_dim) / np.sqrt(input_dim)\n",
    "    wb_model['b1'] = np.zeros((1, hidden_dim))\n",
    "    wb_model['w2'] = np.random.randn(hidden_dim, hidden_dim) / np.sqrt(hidden_dim)\n",
    "    wb_model['b2'] = np.zeros((1, hidden_dim))\n",
    "    wb_model['w3'] = np.random.randn(hidden_dim, output_dim) / np.sqrt(hidden_dim)\n",
    "    wb_model['b3'] = np.zeros((1, output_dim))\n",
    "    return wb_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(model,X):\n",
    "    w1, b1, w2, b2, w3, b3 = model['w1'], model['b1'], model['w2'], model['b2'], model['w3'], model['b3']\n",
    "    #forward_prop\n",
    "    a1 = X.dot(w1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = z1.dot(w2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = z2.dot(w3) + b3\n",
    "    output = Softmax(a3)\n",
    "    return a1,z1,a2,z2,a3,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(model,X,y,reg_lambda):\n",
    "    num_examples = X.shape[0]\n",
    "    w1, b1, w2, b2, w3, b3 = model['w1'], model['b1'], model['w2'], model['b2'], model['w3'], model['b3']\n",
    "    # Forward propagation to calculate our predictions\n",
    "    a1, z1, a2, z2, a3, output = forward_prop(model, X)\n",
    "    probs = output / np.sum(output, axis=1, keepdims=True)\n",
    "    # Calculating the loss\n",
    "    corect_logprobs = -np.log(probs[range(num_examples), y])\n",
    "    loss = np.sum(corect_logprobs)\n",
    "    # Add regulatization term to loss (optional)\n",
    "    loss += reg_lambda/2 * (np.sum(np.square(w1)) + np.sum(np.square(w2)) + np.sum(np.square(w3)))\n",
    "    return 1.0 /num_examples * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(X,y,model,a1,z1,a2,z2,a3,output,reg_lambda):\n",
    "    delta3 = output\n",
    "    delta3[range(X.shape[0]), y] -= 1  #yhat - y\n",
    "    dW3 = (z2.T).dot(delta3)\n",
    "    db3 = np.sum(delta3, axis=0, keepdims=True)\n",
    "    delta2 = delta3.dot(model['w3'].T) * sigmoid_der(z2)\n",
    "    dW2 = np.dot(a1.T, delta2)\n",
    "    db2 = np.sum(delta2, axis=0)\n",
    "    #delta2 = delta3.dot(model['W2'].T) * (1 - np.power(a1, 2)) #if tanh\n",
    "    delta1 = delta2.dot(model['w2'].T) * sigmoid_der(z1)\n",
    "    dW1 = np.dot(X.T, delta1)\n",
    "    db1 = np.sum(delta1, axis=0)\n",
    "    # Add regularization terms\n",
    "    dW3 += reg_lambda * model['w3']\n",
    "    dW2 += reg_lambda * model['w2']\n",
    "    dW1 += reg_lambda * model['w1']\n",
    "    return dW1, dW2, dW3, db1, db2, db3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(X, Y):\n",
    "        # test the model on the training dataset\n",
    "        total_correct = 0\n",
    "        for n in range(len(X)):\n",
    "            y = Y[n]\n",
    "            x = X[n][:]\n",
    "            prediction = np.argmax(forward_prop(x,y)['output'])\n",
    "            if (prediction == y):\n",
    "                total_correct += 1 \n",
    "        print('Accuarcy Test: ',total_correct/len(X_test))\n",
    "        return total_correct/np.float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, iterations, reg_lambda, alpha):\n",
    "    # Batch gradient descent\n",
    "    done = False\n",
    "    previous_loss = float('inf')\n",
    "    i = 0\n",
    "    losses = []\n",
    "     #comment out while performance testing\n",
    "    while i < iterations:\n",
    "        #feed forward\n",
    "        a1,z1,a2,z2,a3,output = forward_prop(model, X)\n",
    "        #backpropagation\n",
    "        dW1, dW2, dW3, db1, db2, db3 = backprop(X,y,model,a1,z1,a2,z2,a3,output,reg_lambda)\n",
    "        #update weights and biases\n",
    "        model['w1'] -= alpha * dW1\n",
    "        model['b1'] -= alpha * db1\n",
    "        model['w2'] -= alpha * dW2\n",
    "        model['b2'] -= alpha * db2\n",
    "        model['w3'] -= alpha * dW3\n",
    "        model['b3'] -= alpha * db3\n",
    "        \n",
    "        loss = cal_loss(model, X, y, reg_lambda)\n",
    "        losses.append(loss)\n",
    "        #uncomment once testing finished, return mod val to 1000\n",
    "        previous_loss = loss\n",
    "        i += 1\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihbor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#input_dim = 784\n",
    "#output_dim = 10\n",
    "wb_model = build_wb(list_train_image,50,10)\n",
    "wb_model_t = build_wb(list_test_image,50,10)\n",
    "wb_model , losses = train(wb_model,list_train_image,list_train_label,iterations,reg_lambda,alpha)\n",
    "wb_model_t, losses_t = train(wb_model_t,list_test_image,list_test_label,iterations,reg_lambda,alpha)\n",
    "output = forward_prop(wb_model,list_train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bf69c39608>]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(losses_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
